{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyGMs Introduction: Exact and Approximate Variable Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyGMs as gm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference is the process of reasoning about the function defined by our graphical model, i.e., the combined influence of all of our factors.  Typical tasks are to compute the sum over all possible configurations, or \"partition function\", which corresponds to the normalizing constant of the function:\n",
    "$$ Z = \\sum_{x} \\prod_\\alpha f_\\alpha(x_\\alpha)$$\n",
    "or the marginal distribution of some variable, say $X_i$, by summing over all variables except $X_i$ and normalizing:\n",
    "$$ p(X_i) = \\frac{1}{Z} \\, \\sum_{x_{\\neg i}} \\prod_\\alpha f_\\alpha(x_\\alpha)$$\n",
    "Maximization tasks compute the most probable configuration, or its value:\n",
    "$$ x^* = \\arg\\max_{x} \\prod_\\alpha f_\\alpha(x_\\alpha)$$\n",
    "$$ f^* = \\max_{x} \\prod_\\alpha f_\\alpha(x_\\alpha)$$\n",
    "More advanced queries may even interleave different types of elimination operations.\n",
    "\n",
    "All these tasks involve the interactions of the entire model and all its factors on joint configurations of $x$, and thus cannot in general be answered without reasoning about the entire graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Model\n",
    "\n",
    "Let us first build a simple graphical model on which to perform our inference tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h,w = 2,4\n",
    "X = [gm.Var(i,3) for i in range(h*w)]\n",
    "tab = np.array([[1,0,0],[0,.9,0],[0,0,.8]])+.1\n",
    "factors  = [gm.Factor([X[h*i+j],X[h*i+j+1]],tab) for i in range(w) for j in range(h-1)]\n",
    "factors += [gm.Factor([X[h*i+j],X[h*i+j+h]],tab) for i in range(w-1) for j in range(h)]\n",
    "\n",
    "pos = {i:(i//h,-(i%h)) for i in range(h*w)}\n",
    "\n",
    "model = gm.GraphModel(factors)\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(5,2)); ax.set_axis_off();\n",
    "gm.drawMarkovGraph(model,node_color='w',ax=ax, pos=pos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Variable Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know how to eliminate variables from our model, altering the structure and factors of our graph.  One way to compute the desired quantity by repeatedly eliminating variables along some order.  However, this will alter the graphical model itself; to avoid this, make a copy first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elim_model = model.copy()\n",
    "elim_model.eliminate([0],'sum')\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(5,2)); ax.set_axis_off();\n",
    "gm.drawMarkovGraph(elim_model,node_color='w',ax=ax, pos=pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elim_model.eliminate([1],'sum')\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(5,2)); ax.set_axis_off();\n",
    "gm.drawMarkovGraph(elim_model,node_color='w',ax=ax, pos=pos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `eliminate` function will also apply elimination sequentially along a desired order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminating all variables leaves us with only a scalar factor:\n",
      "SortedSet([Factor({},[0x23c3f00])], key=<function factorSet.<locals>.<lambda> at 0x7f49d001d820>)\n",
      "with value: [4.56244407]\n",
      "We can also access this with GraphModel.value([]): [4.56244407]\n"
     ]
    }
   ],
   "source": [
    "elim_model.eliminate([2,3,4,5,6,7],'sum')\n",
    "\n",
    "print(\"Eliminating all variables leaves us with only a scalar factor:\")\n",
    "print(elim_model.factors)\n",
    "print(\"with value:\", elim_model.factors[0].table)\n",
    "print(\"We can also access this with GraphModel.value([]):\", elim_model.value([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable elimination using `max` is equally simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max configuration value f* =  [2.59374246]\n"
     ]
    }
   ],
   "source": [
    "elim_model = model.copy()\n",
    "elim_model.eliminate([0,1,2,3,4,5,6,7],'max')\n",
    "print(\"Max configuration value f* = \", elim_model.value([]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimination Orders\n",
    "\n",
    "The computational complexity of variable elimination depends on the structure of the graph and the order in which variables are eliminated.  In our (very regular) example, it is easy to see that the index order is a good one.  If we need to find an elimination order automatically, we can use various heuristic techniques to identify one, such as the \"min width\" or \"min fill\" heuristics.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  [0, 1, 2, 3, 4, 5, 6, 7] ;   score: 58.0\n"
     ]
    }
   ],
   "source": [
    "order, score = gm.eliminationOrder(model, 'minfill')\n",
    "print(\"order: \", order, \";   score:\", score);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns an order, along with a \"score\" corresponding to how large is the collection of intermediate functions that computed by elimination along this order.  This allows us to repeatedly run order searches, and identify better orders when we find them.  The keyword `nExtra` increases the amount of randomness in our search; the default value `nExtra=-1` is deterministic, while `nExtra=0` is greedy but breaks ties randomly, and increasing values of `nExtra` increase variability by making intermediate selections in the algorithm more random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 6, 0, 2, 4, 5, 3, 7], 76.0)\n",
      "([6, 0, 1, 7, 2, 3, 4, 5], 58.0)\n",
      "([7, 0, 1, 6, 4, 5, 3, 2], 58.0)\n",
      "([0, 1, 6, 2, 3, 4, 7, 5], 58.0)\n",
      "([1, 0, 3, 6, 4, 2, 5, 7], 76.0)\n",
      "([6, 0, 7, 4, 2, 5, 1, 3], 76.0)\n",
      "([1, 0, 6, 2, 4, 3, 7, 5], 76.0)\n",
      "([7, 6, 1, 4, 2, 3, 5, 0], 76.0)\n",
      "([0, 1, 6, 7, 4, 5, 3, 2], 58.0)\n",
      "([0, 6, 7, 4, 5, 2, 3, 1], 58.0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print( gm.eliminationOrder(model, 'minfill', nExtra=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we may want to make multiple order search attempts to find a good one.  The algorith can \"short-circuit\" a search and exit with no order if it is already worse than a previously found order, by using the `cutoff` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([6, 7, 1, 4, 5, 3, 2, 0], 58.0)\n",
      "([1, 6, 0, 7, 2, 5, 3, 4], 58.0)\n",
      "(None, 58)\n",
      "([7, 6, 4, 5, 2, 0, 1, 3], 58.0)\n",
      "(None, 58)\n",
      "([0, 6, 7, 4, 1, 3, 2, 5], 58.0)\n",
      "([6, 0, 1, 7, 4, 3, 2, 5], 58.0)\n",
      "([1, 0, 3, 6, 2, 4, 7, 5], 58.0)\n",
      "([6, 7, 5, 4, 3, 2, 0, 1], 58.0)\n",
      "(None, 58)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print( gm.eliminationOrder(model, 'minfill', nExtra=1, cutoff=58) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PseudoTrees\n",
    "\n",
    "Sometimes we want to reason about what *would* happen during variable elimination, without actually performing it.  For example, the preceding elimination process and order created factors with at most two variables at a time, since, for example, eliminating $X_0$ resulted in a new factor over $\\{X_1,X_2\\}$. This \"largest clique size\" during elimination is called the *induced width* of the elimination order.\n",
    "\n",
    "A useful structure for representing the elimination process, without computing the factors and tables involved, is a **pseudotree**.  The pseudotree follows the elimination process, keeping track of what factors would be created and combined.  Some useful statistics of the resulting structure are its *width* (the number of arguments to the largest factor created during the elimination), and its *depth*, the longest sequence of dependencies during the elimination process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PseudoTree has width 2 and depth 7\n",
      "Estimated computational effort is 58.0\n"
     ]
    }
   ],
   "source": [
    "pt = gm.PseudoTree(model, order)\n",
    "print(f\"PseudoTree has width {pt.width} and depth {pt.depth}\")\n",
    "print(f\"Estimated computational effort is {pt.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junction Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the direct variable elimination process does not save the intermediate quantities needed for answering other queries, such as finding the configuration $x^*$ corresponding to value $f^*$, or computing marginal probabilities (other than that of the last eliminated variable).  These computations are usually performed using message passing on a junction tree or equivalent representation of the cliques.\n",
    "\n",
    "The junction tree implementation is part of a more general approximation technique called weighted mini-bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyGMs.wmb\n",
    "\n",
    "jt = gm.wmb.JTree(model, order,'sum+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Here, \"+\" indicates that in the more general, WMB approximation, an upper bound should be computed.)\n",
    "\n",
    "The junction tree representes the cliques that are reasoned about jointly during the elimination process, and how the results of each elimination are used in subsequent calculations.  If we display the internal representation, we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000: {0,1,2} => (1); \n",
       "001: {1,2,3} => (2); \n",
       "002: {2,3,4} => (3); \n",
       "003: {3,4,5} => (4); \n",
       "004: {4,5,6} => (5); \n",
       "005: {5,6,7} => (6); \n",
       "006: {6,7} => (7); \n",
       "007: {7} => (None); "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row corresponds to the elimination of a variable along our order, here $X_0$ to $X_7$; then we see the clique, or scope of the joint function computed.  So again, we see that when eliminating $X_0$, we reason about $(X_0,X_1,X_2)$, and the resulting quantity (a message involving $X_1$ and $X_2$) is passed along to be used in the elimination of $X_1$.\n",
    "\n",
    "The \"forward pass\" on a junction tree computes the same quantity as elimination along that ordering, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log partition function:  1.5178584609923864\n",
      "   (so, Z =  4.562444073600002 )\n"
     ]
    }
   ],
   "source": [
    "lnZ = jt.msgForward()\n",
    "print(\"Log partition function: \",lnZ)\n",
    "print(\"   (so, Z = \",np.exp(lnZ),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the junction tree also stores the intermediate computations, allowing us to then perform a backward pass to find any desired marginals, indicated by a list of `gm.VarSet`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{0}: Factor({0},[0x25d3ee0]), {2,3}: Factor({2,3},[0x1fb6870]), {5}: Factor({5},[0x1f2b5c0])}\n",
      "\n",
      "p(X0) =  [0.6299893 0.2620805 0.1079302]\n",
      "p(X2,X3) =  [[0.63671452 0.00263251 0.00208032]\n",
      " [0.00263251 0.25569223 0.00146849]\n",
      " [0.00208032 0.00146849 0.0952306 ]]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "queries = [ gm.VarSet([X[0]]) , gm.VarSet([X[2],X[3]]), gm.VarSet([X[5]]) ]\n",
    "marginals = jt.beliefs( queries )\n",
    "print(marginals)\n",
    "print()\n",
    "print(\"p(X0) = \", marginals[queries[0]].table)\n",
    "print(\"p(X2,X3) = \", marginals[queries[1]].table)\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, draw samples from the normalized version of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({Var (7,3): 0, Var (6,3): 0, Var (5,3): 0, Var (4,3): 0, Var (3,3): 0, Var (2,3): 0, Var (1,3): 0, Var (0,3): 0}, -0.5647566629491377)\n",
      "({Var (7,3): 1, Var (6,3): 1, Var (5,3): 1, Var (4,3): 1, Var (3,3): 1, Var (2,3): 1, Var (1,3): 1, Var (0,3): 1}, -1.5178584609923862)\n",
      "({Var (7,3): 0, Var (6,3): 0, Var (5,3): 0, Var (4,3): 0, Var (3,3): 0, Var (2,3): 0, Var (1,3): 0, Var (0,3): 0}, -0.5647566629491377)\n",
      "({Var (7,3): 0, Var (6,3): 0, Var (5,3): 0, Var (4,3): 0, Var (3,3): 0, Var (2,3): 0, Var (1,3): 0, Var (0,3): 1}, -5.360547208545879)\n",
      "({Var (7,3): 1, Var (6,3): 1, Var (5,3): 1, Var (4,3): 1, Var (3,3): 1, Var (2,3): 1, Var (1,3): 1, Var (0,3): 1}, -1.5178584609923862)\n"
     ]
    }
   ],
   "source": [
    "for i  in range(5):\n",
    "    print( jt.sample() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that computing the marginals requires that our junction tree is created using \"sum\" inference operations.  By computing a junction tree using \"max\" operations, we can find the value of, and a configuration for, the most probable state of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal log value:  0.9531017980432497\n",
      "   (so, f-star =  2.5937424601000028 )\n",
      "An optimal configuration is: \n",
      "   {Var (7,3): 0, Var (6,3): 0, Var (5,3): 0, Var (4,3): 0, Var (3,3): 0, Var (2,3): 0, Var (1,3): 0, Var (0,3): 0}\n"
     ]
    }
   ],
   "source": [
    "jt = gm.wmb.JTree(model, order,'max+')\n",
    "lnf = jt.msgForward()\n",
    "print(\"Optimal log value: \",lnf)\n",
    "print(\"   (so, f-star = \",np.exp(lnf),\")\")\n",
    "print(\"An optimal configuration is: \")\n",
    "print(\"  \",jt.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Mini-Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the exact variable elimination process is too computationally expensive, we can approximate it using \"mini-buckets\", which approximate the elimination at each step using an approximate elimination whose resulting function is made up of smaller, more managable factors, and which bounds the correct function in some way.\n",
    "\n",
    "Mini-bucket does this by not combining all the factors of a given bucket, leaving multiple \"mini-buckets\", then eliminating separately in each mini-bucket.  We can see how this works with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000: {0,1}^0.50 => (1, 0); {0,2}^0.50 => (2, 0); \n",
      "001: {1,3}^1.00 => (3, 0); \n",
      "002: {2,3}^0.50 => (3, 0); {2,4}^0.50 => (4, 0); \n",
      "003: {3,5}^1.00 => (5, 0); \n",
      "004: {4,5}^0.50 => (5, 0); {4,6}^0.50 => (6, 0); \n",
      "005: {5,7}^1.00 => (7, 0); \n",
      "006: {6,7}^1.00 => (7, 0); \n",
      "007: {7}^1.00 => (None, None); \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wmb = gm.wmb.WMB(model, order,iBound=1, weights='sum+')\n",
    "print(wmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that, when eliminating $X_0$, we group our factors into two sets, called mini-buckets: one including only variables $(X_0,X_1)$ and the other including only variables $(X_0,X_2)$. We then eliminate $X_0$ within each set separately, using a \"weighted sum\" with weight 0.5 in each mini-bucket, producing an upper bound on the true functon of $(X_1,X_2)$ defined by a function over only $X_1$ (which is passed to mini-bucket 0 in bucket 1, i.e., when eliminating $X_1$) and another function only over $X_2$ (which is passed to mini-bucket 0 of bucket 2, when $X_2$ is eliminated).  The computation never produces messages (intermediate factors) with more than `iBound` arguments, controlling the computational and memory complexity of the algorithm.\n",
    "\n",
    "As with the junction tree, we can use a forward pass to compute the corresponding upper bound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln Z <  2.064044538592766\n"
     ]
    }
   ],
   "source": [
    "lnZ_bound = wmb.msgForward()\n",
    "print(\"ln Z < \",lnZ_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only an approximation, however, and can be tightened through changes to to allocation of factors to mini-buckets (called \"reparameterization\"), and by changes to the weights associated with each mini-bucket.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln Z <  2.0612518973513887\n",
      "ln Z <  2.059197076394305\n",
      "ln Z <  2.0576782054186378\n",
      "ln Z <  2.056550417597293\n"
     ]
    }
   ],
   "source": [
    "for step in range(4):\n",
    "    wmb.msgBackward( stepTheta=.5, stepWeights=.2 )\n",
    "    print(\"ln Z < \",wmb.msgForward())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each iteration tries to reduce the bound through a gradient update to the parameters and weights, with step sizes controlled by `stepTheta` (reparameterization changes) and `stepWeights` (weight changes).\n",
    "\n",
    "As with the junction tree, this representation can be used to compute *approximate* marginals (called \"beliefs\"), or draw samples from a distribution that uses the mini-bucket bound to approximate the true distribution.\n",
    "\n",
    "Using `weights=max+` produces a corresponding upper bound on the max-inference junction tree, which again can be tightened through reparameterization.  (Here, the weights are all zero and cannot be changed to tighten the bound.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln F* <  0.9975424744084762\n",
      "  ln F* <  0.9953270843347504\n",
      "  ln F* <  0.9942725535046908\n",
      "  ln F* <  0.9937193021820291\n",
      "  ln F* <  0.9933988828603257\n"
     ]
    }
   ],
   "source": [
    "wmb = gm.wmb.WMB(model, order,iBound=1, weights='max+')\n",
    "print(\"ln F* < \",wmb.msgForward())\n",
    "for step in range(4):\n",
    "    wmb.msgBackward( stepTheta=.5 )\n",
    "    print(\"  ln F* < \",wmb.msgForward())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the complexity control parameter *iBound* increases, we reason about larger functions, until at some point the functions are sufficiently large to perform exact inference.  For example, in this model, the induced width is 2, so with iBound=3, we obtain the same results as the junction tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000: {0,1,2}^1.00 => (1, 0); \n",
      "001: {1,2,3}^1.00 => (2, 0); \n",
      "002: {2,3,4}^1.00 => (3, 0); \n",
      "003: {3,4,5}^1.00 => (4, 0); \n",
      "004: {4,5,6}^1.00 => (5, 0); \n",
      "005: {5,6,7}^1.00 => (6, 0); \n",
      "006: {6,7}^1.00 => (7, 0); \n",
      "007: {7}^1.00 => (None, None); \n",
      "\n",
      "With iBound=3, lnZ=1.5178584609923864\n"
     ]
    }
   ],
   "source": [
    "wmb3 = gm.wmb.WMB(model, order,iBound=3, weights='sum+')\n",
    "print(wmb3)\n",
    "print(f'With iBound=3, lnZ={wmb3.msgForward()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also start with a low-width minibucket model, and increase its width later by merging cliques or adding larger cliques.  For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iBound=1 lnZ=2.064044538592766\n",
      "\n",
      "Now, if we add a few, larger cliques, e.g., {0,1,2}, {2,3,4},\n",
      "we see that the resulting mini-bucket tree has a few larger cliques:\n",
      "000: {0,1,2}^1.00 => (1, 1); \n",
      "001: {1,3}^1.00 => (3, 0); {1,2}^0.00 => (2, 0); \n",
      "002: {2,3,4}^1.00 => (3, 1); \n",
      "003: {3,5}^1.00 => (5, 0); {3,4}^0.00 => (4, 0); \n",
      "004: {4,5}^0.50 => (5, 0); {4,6}^0.50 => (6, 0); \n",
      "005: {5,7}^1.00 => (7, 0); \n",
      "006: {6,7}^1.00 => (7, 0); \n",
      "007: {7}^1.00 => (None, None); \n",
      "\n",
      "New WMB bound lnZ=2.0617528495675574\n"
     ]
    }
   ],
   "source": [
    "wmb = gm.wmb.WMB(model, order,iBound=1, weights='sum+')\n",
    "print(f'iBound=1 lnZ={wmb.msgForward()}')\n",
    "print()\n",
    "print('Now, if we add a few, larger cliques, e.g., {0,1,2}, {2,3,4},')\n",
    "wmb.addClique([0,1,2])\n",
    "wmb.addClique([2,3,4])\n",
    "print('we see that the resulting mini-bucket tree has a few larger cliques:')\n",
    "print(wmb)\n",
    "print(f'New WMB bound lnZ={wmb.msgForward()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With fewer approximations, this typically provides a better bound.  We can merge cliques automatically using some score function to tell us which cliques are valid to merge, and an order of preference; for example, the iBound mechanism can be reproduced using a simple merge strategy that allows merges up to scope size (number of variables) iBound, and prefers to merge larger cliques if possible, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000: {0,1,2}^1.00 => (1, 0); \n",
      "001: {1,2,3}^1.00 => (2, 0); \n",
      "002: {2,3,4}^1.00 => (3, 0); \n",
      "003: {3,4,5}^1.00 => (4, 0); \n",
      "004: {4,5,6}^1.00 => (5, 0); \n",
      "005: {5,6,7}^1.00 => (6, 0); \n",
      "006: {6,7}^1.00 => (7, 0); \n",
      "007: {7}^1.00 => (None, None); \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wmb.merge( wmb.scoreByScope(ibound=3) )\n",
    "print(wmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
