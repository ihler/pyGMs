{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyGMs Introduction: Monte Carlo Approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyGMs as gm\n",
    "import pyGMs.montecarlo   # get Monte Carlo sub-functions\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo approximations are a set of methods to approximate inference (answering queries about our model) using randomness.  These usually rely on writing our inference queries as expectations, i.e., averages over the probability distribution $p(x)$ defined by our model, and then using random samples to approximate these expectations.  However, since our graphical model may contain many complex interactions, directly sampling from it may not be easy.\n",
    "\n",
    "In general, Monte Carlo approximations fall into two broad categories: **importance sampling** methods, which draw samples from an easy-to-sample surrogate distribution (called the \"proposal distribution\") and then \"adjusts\" these samples to represent our target model $p(x)$; and **Markov chain Monte Carlo**, which uses a random simulation process that, if run for sufficently long (read: impractically long), would generate samples from $p(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Model\n",
    "\n",
    "Let us first build a simple graphical model on which to perform our inference tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h,w = 3,4\n",
    "X = [gm.Var(i,3) for i in range(h*w)]\n",
    "tab = np.array([[1,0,0],[0,.9,0],[0,0,.8]])+.1\n",
    "factors  = [gm.Factor([X[h*i+j],X[h*i+j+1]],tab) for i in range(w) for j in range(h-1)]\n",
    "factors += [gm.Factor([X[h*i+j],X[h*i+j+h]],tab) for i in range(w-1) for j in range(h)]\n",
    "\n",
    "pos = {i:(i//h,-(i%h)) for i in range(h*w)}\n",
    "\n",
    "model = gm.GraphModel(factors)\n",
    "\n",
    "order = list(range(w*h))            # default elimination order\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(5,3)); ax.set_axis_off();\n",
    "gm.drawMarkovGraph(model,node_color='w',ax=ax, pos=pos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling-based estimators\n",
    "\n",
    "If we can generate exact samples from a distribution, we can use empirical frequncies to estimate values.  However, our model is not in a form that is easy to sample.  If we find the sequence of probabilities $p(X_0)$, $p(X_1|X_0)$, ... $p(X_n|\\ldots)$, we can use forward sampling to draw a value $x_0$, then $x_1$ given our sampled $x_0$, and so forth.  But, finding these probabilities requires inference.  We can use a *junction tree* inference algorithm to compute these probabilities, after which we could then draw samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X0) ~  [0.82 0.16 0.02]\n",
      "p(X3,X4) ~  [[0.82 0.   0.  ]\n",
      " [0.   0.16 0.  ]\n",
      " [0.01 0.   0.01]]\n"
     ]
    }
   ],
   "source": [
    "import pyGMs.wmb\n",
    "\n",
    "jt = gm.wmb.JTree(model, order,'sum+')   # do the work to find f(x)'s normalized sampling distribution\n",
    "\n",
    "samples = gm.d2t([jt.sample()[0] for s in range(100)])  # draw samples\n",
    "\n",
    "beliefs = gm.misc.empirical( [ [X[0]], [X[3],X[4]] ] , samples, normalize=True)  # estimate frequencies\n",
    "\n",
    "print('p(X0) ~ ',beliefs[0].table)\n",
    "print('p(X3,X4) ~ ',beliefs[1].table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic sampling estimators\n",
    "\n",
    "If we do not want to compute the exact $p(X)$ -- for example, if the graph has high width -- we can define a simpler proposal and use an importance sampling estimator.  Since sampling operators return both a configuration $x$ and the probability of generating $x$, a basic importance sampler is easy:\n",
    "\n",
    "We first create an easy-to-sample-from distribution.  In this case, we will just select a tree-structured sub-graph of our full model. (Alternatively, we could get a distribution from an approximate inference algorithm, such as weighted mini-bucket (WMB), for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "span_tree = factors[:h-1] + factors[w*(h-1):]\n",
    "tree_submodel = gm.GraphModel(span_tree)\n",
    "tree_order,_ = gm.eliminationOrder(tree_submodel, 'minwidth')\n",
    "proposal = gm.wmb.JTree(tree_submodel, tree_order, 'sum+')  # cheap: tree is only width 1\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(5,3)); ax.set_axis_off();\n",
    "gm.drawMarkovGraph(tree_submodel,node_color='w',ax=ax, pos=pos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importance sampling estimator draws samples $x\\sim q(X)$, and assigns them an importance weight given by $w = f(x)/q(x)$.  Then, we can estimate queries using these weighted samples.  A common estimator is the self-normalized importance sampler, in which we collect the weights, normalize them, and then use the weighted empirical expectations for our queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X0) ~  [0.76948977 0.22949689 0.00101335]\n",
      "p(X3,X4) ~  [[8.48589703e-01 4.52602264e-04 6.57859913e-05]\n",
      " [1.78389829e-04 1.49170405e-01 4.06543144e-04]\n",
      " [1.19298477e-04 5.43693993e-04 4.73578802e-04]]\n"
     ]
    }
   ],
   "source": [
    "draws = [ (x,model.logValue(x)-lnw) for s in range(100) for x,lnw in [proposal.sample()] ]\n",
    "samples, log_weights = gm.d2t([x for x,wt in draws]), [lnw for x,lnw in draws]\n",
    "\n",
    "weights_selfnorm = np.exp( np.array(log_weights) );\n",
    "weights_selfnorm /= weights_selfnorm.sum()\n",
    "\n",
    "beliefs = gm.misc.empirical( [ [X[0]], [X[3],X[4]] ] , samples, weights_selfnorm)  # estimate frequencies\n",
    "\n",
    "print('p(X0) ~ ',beliefs[0].table)\n",
    "print('p(X3,X4) ~ ',beliefs[1].table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this is reasonably accurate compared to the exact sampler with a similar number of draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online estimation of expectations\n",
    "\n",
    "We may not want to store all of the samples we are drawing, since we are really only interested in the resulting estimates.  `pyGMs` has some data structures for maintaining online estimates of empirical quantities, specifically for Monte Carlo methods.\n",
    "\n",
    "Suppose we want to estimate the expected value of some function, e.g. $g(x) = x_1/(x_2+1)$.  We can create an object that tracks this expectation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 samples, estimate: [0.02542452]\n",
      "20 samples, estimate: [0.0270161]\n",
      "30 samples, estimate: [0.02918323]\n",
      "40 samples, estimate: [0.02555842]\n",
      "50 samples, estimate: [0.02748369]\n",
      "60 samples, estimate: [0.02935625]\n",
      "70 samples, estimate: [0.02864389]\n",
      "80 samples, estimate: [0.03172661]\n",
      "90 samples, estimate: [0.03226535]\n",
      "100 samples, estimate: [0.02947861]\n"
     ]
    }
   ],
   "source": [
    "g = lambda x: x[1]/(x[2]+1)\n",
    "\n",
    "stats = gm.montecarlo.EmpiricalStatistics(g)\n",
    "\n",
    "for s in range(100):\n",
    "    x,lnw = proposal.sample(); \n",
    "    wt = np.exp(model.logValue(x)-lnw);\n",
    "    stats.update(x,wt)\n",
    "    if (s+1)%10==0: print(f'{s+1} samples, estimate: {stats()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check some basic statistics about the data that have been accumulated, such as the \"effective number of samples\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 99 samples, our effective number of samples is [24.02650633]\n"
     ]
    }
   ],
   "source": [
    "print(f'After {s} samples, our effective number of samples is {stats.neff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to track multiple expectations, we can give them as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 samples, estimate: [0.018726908109627634, 0.03745381621925527]\n",
      "20 samples, estimate: [0.020126291365294504, 0.03522100988926538]\n",
      "30 samples, estimate: [0.013811452958629889, 0.03255556768819902]\n",
      "40 samples, estimate: [0.024242144038908744, 0.07532380469232358]\n",
      "50 samples, estimate: [0.03600572948436801, 0.08289691206866122]\n",
      "60 samples, estimate: [0.0451263744039589, 0.10069521561213966]\n",
      "70 samples, estimate: [0.04112396253693945, 0.09504204675203781]\n",
      "80 samples, estimate: [0.03940024988726575, 0.09706551627856194]\n",
      "90 samples, estimate: [0.04378294685400673, 0.1057008421090813]\n",
      "100 samples, estimate: [0.043878220116250186, 0.10782839198780628]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mk/c779r669401fcm1j1n9x37v80000gn/T/ipykernel_35444/3138104555.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  wt = float(np.exp(model.logValue(x)-lnw));\n"
     ]
    }
   ],
   "source": [
    "g2 = lambda x: x[0]*x[1]\n",
    "\n",
    "stats = gm.montecarlo.EmpiricalStatistics([g,g2])\n",
    "\n",
    "for s in range(100):\n",
    "    x,lnw = proposal.sample(); \n",
    "    wt = float(np.exp(model.logValue(x)-lnw));\n",
    "    stats.update(x,wt)\n",
    "    if (s+1)%10==0: print(f'{s+1} samples, estimate: {stats()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, what we want are the marginal probabilities of *many* sub-configurations of the model, e.g., the marginal distribution $p(X_1,X_2)$, etc. There is a specialized object for tracking the marginal probabilites of `VarSet`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal probability of 1st factor, mu(X{0,1}): \n",
      "[[8.27255990e-01 6.92913150e-05 3.46283433e-08]\n",
      " [6.44571983e-04 1.51158744e-01 2.59366292e-05]\n",
      " [6.23310180e-07 3.49746268e-06 2.08413108e-02]]\n"
     ]
    }
   ],
   "source": [
    "marg = gm.montecarlo.EmpiricalMarginals( model.factors )  # get marginals of all factors\n",
    "for s in range(100):\n",
    "    x,lnw = proposal.sample(); \n",
    "    marg.update(x,np.exp(model.logValue(x)-lnw))\n",
    "print(f'Marginal probability of 1st factor, mu(X{marg[0].vars}): \\n{marg[0].table}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to draw samples for a fixed amount of time, there is a helper function that can assist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drew 14399.0 samples, Neff [2547.92546172]: [array([0.04051948]), array([0.11051306])]\n"
     ]
    }
   ],
   "source": [
    "stats.reset()                  # reset sample accumulation\n",
    "\n",
    "for t in gm.timelimit(10):        # ~10 second time limit\n",
    "    x,lnw = proposal.sample();\n",
    "    stats.update(x,np.exp(model.logValue(x)-lnw))\n",
    "print(f'Drew {stats.nsamples} samples, Neff {stats.neff}: {stats()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo\n",
    "\n",
    "The other basic strategy of Monte Carlo methods is to form a sequential, stochastic process (\"Markov chain\") which, when simulated, will *eventually* result in a sample from the target distribution $p(X)$.  There are many approaches, but the two most common are Gibbs sampling and its variants, and the slightly more general Metropolis-Hastings algorithm.\n",
    "\n",
    "In general, since MCMC approaches are designed to give samples (asymptotically) from $p(X)$, we do not associate the samples with a weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs Sampling\n",
    "The simplest MCMC sampler is the Gibbs sampler, which stochastically updates one (or a few) variables at a time, given the current values of the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zeros = (0,)*len(model.X)   # we may want to start the chain in a known state\n",
    "\n",
    "gs = pyGMs.montecarlo.GibbsSampler(model,chains=1, init_states=[all_zeros])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each call to ``sample()`` performs one or more forward steps of the Markov chain simulation process.  You can \"burn in\" (move away from the initial condition) $T$ steps by calling `sample()` $T$ times, or by calling ``sample(T)``.  Then, to decimate the chain by some amount $t$, you can generate each subsequent sample by calling ``sample(t)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X0) ~  [0.99 0.01 0.  ]\n",
      "p(X3,X4) ~  [[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "_ = gs.sample(10)                               # burn in by 10 steps\n",
    "samples = [gs.sample(5)[0] for i in range(100)] # Generate 100 samples, each 5 steps apart\n",
    "\n",
    "beliefs = gm.misc.empirical( [ [X[0]], [X[3],X[4]] ] , samples, normalize=True)  # estimate frequencies\n",
    "\n",
    "print('p(X0) ~ ',beliefs[0].table)\n",
    "print('p(X3,X4) ~ ',beliefs[1].table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> TODO: TBD </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annealed Importance Sampling\n",
    "\n",
    "AIS is an algorithm that uses MCMC to produce samples, but does so within an importance sampling framework, so that the nice properties of importance sampling can be preserved.  It does more work per sample than standard IS, but (hopefully) results in samples that are closer to the target distribution $p(X)$, and thus a higher effective sample size.\n",
    "\n",
    "To use AIS, we need a \"base\" proposal distribution that is represented as a Bayesian network, so that it can be both forward-sampled and used in MCMC.  For demonstration, we will make a base that is an independent distribution, with single-variable probabilities obtained through a WMB approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmb = gm.wmb.WMB(model,order,iBound=1,weights='sum+')\n",
    "wmb.msgForward(0.5,0.0)\n",
    "mu = wmb.msgBackward(0,0, beliefs=[gm.VarSet([x]) for x in model.X])\n",
    "base = gm.GraphModel([mu[f] for f in mu])\n",
    "\n",
    "# Can verify that the resulting model is a Bayes net, if desired:\n",
    "# base_order=gm.bnOrder(base)\n",
    "# base.isBN()\n",
    "# gm.bnSample(base,base_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), array([-6.47120408]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.montecarlo.AnnealedImportanceSampling(model,None,base,T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X0) ~  [9.99968427e-01 1.11990054e-08 3.15615851e-05]\n",
      "p(X3,X4) ~  [[9.99999989e-01 0.00000000e+00 0.00000000e+00]\n",
      " [1.11990054e-08 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mk/c779r669401fcm1j1n9x37v80000gn/T/ipykernel_35444/376270306.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  samples, log_weights = [x for x,wt in draws], [float(wt) for x,wt in draws]\n"
     ]
    }
   ],
   "source": [
    "draws = [ gm.montecarlo.AnnealedImportanceSampling(model,None,base,T=10,K=5) for s in range(100)]\n",
    "\n",
    "samples, log_weights = [x for x,wt in draws], [float(wt) for x,wt in draws]\n",
    "\n",
    "weights_selfnorm = np.exp(model.logValue(samples)-log_weights);\n",
    "weights_selfnorm /= weights_selfnorm.sum()\n",
    "\n",
    "beliefs = gm.misc.empirical( [ [X[0]], [X[3],X[4]] ] , samples, weights_selfnorm)  # estimate frequencies\n",
    "\n",
    "print('p(X0) ~ ',beliefs[0].table)\n",
    "print('p(X3,X4) ~ ',beliefs[1].table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base distribution IS gives Neff=[2.28966462] at 100.0 samples\n"
     ]
    }
   ],
   "source": [
    "margIS  = gm.montecarlo.EmpiricalMarginals( model.factors ) \n",
    "\n",
    "base_order=gm.bnOrder(base)\n",
    "for s in range(100):\n",
    "    x,lnw = gm.bnSample(base, base_order)\n",
    "    margIS.update(x,np.exp(model.logValue(x)-lnw))\n",
    "    \n",
    "print(f'Base distribution IS gives Neff={margIS.neff} at {margIS.nsamples} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIS with 20 temps, 1 step(s) per temp gives Neff=[3.96571482] at 100.0 samples\n"
     ]
    }
   ],
   "source": [
    "margAIS = gm.montecarlo.EmpiricalMarginals( model.factors ) \n",
    "\n",
    "T=20; K=1;\n",
    "for s in range(100):\n",
    "    x,lnw = gm.montecarlo.AnnealedImportanceSampling(model,None,base,T=T,K=K)\n",
    "    margAIS.update(x,np.exp(model.logValue(x)-lnw))\n",
    "    \n",
    "print(f'AIS with {T} temps, {K} step(s) per temp gives Neff={margAIS.neff} at {margAIS.nsamples} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
